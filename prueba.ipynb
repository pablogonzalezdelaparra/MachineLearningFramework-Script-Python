{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el modelo se ajusta bastante bien a los datos de entrenamiento, es importante que podamos predecir los datos que no se han visto antes. De lo contrario, el modelo no será útil para predecir nuevos datos. Esto se conoce como sobreajuste (overfitting) y ocurre cuando el modelo se ajusta demasiado bien a los datos de entrenamiento y no generaliza bien a los datos nuevos. Hay varias formas de mitigar el sobreajuste, como la regularización. A continuación, se muestra la utilización de dos técnicas de regularización: la regularización L1 y la regularización L2 para intentar mejorar el modelo. \n",
    "Como se puede observar antes de la regularización, el modelo tiene una precisión del 81%, lo que significa que el 81% de las predicciones positivas son correctas. Sin embargo, cuando se observa la gráfica de ROC se puede notar que existe un poco de mejora que se puede realizar para que el incremento de la tasa de verdaderos positivos sea mayor. Esto nos lleva a aplicar la regularización. Al aplicar la regularización L1 (Lasso) se puede observar que la precisión del modelo es ligeramente mejor que la del modelo sin regularización (lr0), lo que indica que la regularización L1 ha mejorado el rendimiento en términos de precisión. Por otro lado, al aplicar la regularización L2 (Ridge) se puede observar que la precisión del modelo es similar a la del modelo sin regularización (lr0), lo que indica que la regularización L2 no ha tenido un impacto significativo en la precisión. Esto nos puede indicar ciertas cosas como las siguientes:\n",
    "* La regularización L1 (Lasso) tiende a ser útil cuando se sospecha que algunas características son irrelevantes y se desea una selección automática de características.\n",
    "* La regularización L2 (Ridge) tiende a ser útil cuando se desea evitar el sobreajuste sin necesariamente eliminar características.\n",
    "Por lo que nuestro dataset, al mejorar con la regularización L1 (Lasso), nos indica que algunas características son irrelevantes y al realizar la selección automática de características, se mejora la precisión del modelo. \n",
    "\n",
    "En temas más específicos, al tomar la gráfica de precision-recall, el modelo sin regularización tiene un mayor recall que el modelo con regularización L1 (Lasso), lo que indica que el modelo sin regularización tiene un mejor rendimiento en términos de determinar que tan bueno es el modelo para predecir los positivos. Al igual que en la gráfica de comparación de F1-score en donde en la regularización L1 es mayor, lo que nos indica que el modelo sin regularización tiene un mejor rendimiento en términos de precisión y recall de manera general.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnóstico y explicación el nivel de ajuste del modelo: underfit, fit, overfit\n",
    "Utiliza gráficas comparativos del aprendizaje del conjunto de entrenamiento prueba y validación, para explicar.\n",
    "\n",
    "De acuerdo con los resultados tanto de precisión como de la comparación de las gráfica sobre el rendimiento del modelo sobre cada subset de datos, se puede observar que el modelo presenta un nivel de ajuste fit. Esto debido a distintas razones. La primer se puede notar que la calificación de las precisiones a lo largo de las 3 divisiones del dataset (train, validación y testing) se obtienen valores similares, lo que nos indica que el modelo no presenta un sobreajuste (overfitting) ni un subajuste (underfitting), porque si tuviera un sobreajuste, la precisión del modelo en el conjunto de entrenamiento sería mucho mayor que la precisión en el conjunto de validación y si tuviera un subajuste, la precisión del modelo en el conjunto de entrenamiento sería mucho menor que la precisión en el conjunto de validación. Cuando se realiza la función de cross-validation, se puede observar que la precisión del modelo en un promedio de 10 divisiones del dataset es casi del 80%, lo que nos indica que el modelo presenta un nivel de ajuste fit al no tener desviaciones significativas en la precisión del modelo en cada división del dataset. Por otro lado, al observar las gráficas de comparación de las curvas de aprendizaje, se puede notar que el modelo presenta un nivel de ajuste fit, ya que las curvas de aprendizaje convergen a un valor similar, lo que nos indica que el modelo no presenta un sobreajuste (overfitting) ni un subajuste (underfitting), porque si por ejemplo tuviera un sobreajuste, la curva de aprendizaje del conjunto de entrenamiento convergería a un valor mayor que la curva de aprendizaje del conjunto de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con el cálculo y las gráficas anteriores,  La precisión de nuestro modelo entrenado sobre datos nunca antes vistos (test) es de 0.81, lo que nos indica que no existe un sesgo relevante que este afectando el modelo. Esto se puede comprobar al realizar el cálculo que realiza sobre la predicción de las distintas clases. En este caso, tanto la clase 0 (0) como la clase 1 (1) demuestra que la predicción del modelo genera una distribución similar a la distribución real de los datos. Esto nos indica que la predicción de dichas clase se realiza de manera exitosa. Esto también demuestra que el modelo no tiene una precisión con un nivel alto debido a que una clase tiene una mayor cantidad de datos que la otra, sino que el modelo es capaz de predecir de manera exitosa ambas clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con la definición de la varianza, la varianza es una medida de la variabilidad de los datos de un conjunto de datos. En este caso, la varianza del modelo es baja. Esto demostrado al dividir el set de testing en 10 partes, mostrando el rendimiento del modelo entrenado en cada una de las partes. Como se puede observar, la varianza del modelo es baja, ya que la precisión del modelo en cada una de las partes es similar. Esto nos indica que el modelo no presenta un sobreajuste (overfitting) ni un subajuste (underfitting). De igual manera, esto se puede demostrar con la gráfica de precisión del modelo en cada una de las partes. En este caso se utiliza esta división de test debido a que como estos datos no han sido vistos por el modelo, se puede observar que el rendimiento generaliza con datos nuevos sin tener una diferencia significativa en la precisión de cada uno de estos segmentos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
